'''
# 05 – Predictive Modeling
## Brain Cancer Gene Expression (CuMiDa – GSE50161)

Objectives:
- Train supervised classifiers using selected gene features
- Evaluate performance with robust metrics
- Compare linear and nonlinear models
- Establish a strong diagnostic baseline

Models:
- ElasticNet Logistic Regression
- Random Forest
- CatBoost (tabular best-in-class)
'''

import pandas as pd
import numpy as np

from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import StratifiedKFold, cross_val_predict
from sklearn.metrics import (
    accuracy_score,
    f1_score,
    classification_report,
    confusion_matrix
)

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier

from catboost import CatBoostClassifier

import matplotlib.pyplot as plt
import seaborn as sns

sns.set_style("whitegrid")

samples = pd.read_csv("../data/processed/samples.csv")
expression = pd.read_csv("../data/processed/expression_matrix.csv")
selected_genes = pd.read_csv("../data/processed/selected_genes.csv")

selected_genes.shape

X = (
    expression[
        expression["gene_id"].isin(selected_genes["gene_id"])
    ]
    .pivot(index="sample_id", columns="gene_id", values="expression_value")
    .sort_index()
)

y = samples.sort_values("sample_id")["label"].values

X.shape

le = LabelEncoder()
y_encoded = le.fit_transform(y)

class_names = le.classes_
class_names

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

cv = StratifiedKFold(
    n_splits=5,
    shuffle=True,
    random_state=42
)

log_reg = LogisticRegression(
    penalty="elasticnet",
    solver="saga",
    l1_ratio=0.5,
    max_iter=5000,
    class_weight="balanced"
)

y_pred_lr = cross_val_predict(
    log_reg,
    X_scaled,
    y_encoded,
    cv=cv
)

print("ElasticNet Logistic Regression")
print("Accuracy:", accuracy_score(y_encoded, y_pred_lr))
print("Macro F1:", f1_score(y_encoded, y_pred_lr, average="macro"))
print(classification_report(y_encoded, y_pred_lr, target_names=class_names))

rf = RandomForestClassifier(
    n_estimators=500,
    max_depth=None,
    class_weight="balanced",
    random_state=42,
    n_jobs=-1
)

y_pred_rf = cross_val_predict(
    rf,
    X,
    y_encoded,
    cv=cv
)

print("Random Forest")
print("Accuracy:", accuracy_score(y_encoded, y_pred_rf))
print("Macro F1:", f1_score(y_encoded, y_pred_rf, average="macro"))
print(classification_report(y_encoded, y_pred_rf, target_names=class_names))

cat = CatBoostClassifier(
    iterations=1000,
    depth=6,
    learning_rate=0.05,
    loss_function="MultiClass",
    eval_metric="TotalF1",
    verbose=False,
    random_seed=42
)

y_pred_cat = cross_val_predict(
    cat,
    X,
    y_encoded,
    cv=cv
)

print("CatBoost")
print("Accuracy:", accuracy_score(y_encoded, y_pred_cat))
print("Macro F1:", f1_score(y_encoded, y_pred_cat, average="macro"))
print(classification_report(y_encoded, y_pred_cat, target_names=class_names))

cm = confusion_matrix(y_encoded, y_pred_cat)

plt.figure(figsize=(8, 6))
sns.heatmap(
    cm,
    annot=True,
    fmt="d",
    cmap="Blues",
    xticklabels=class_names,
    yticklabels=class_names
)
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("CatBoost Confusion Matrix")
plt.show()

results = pd.DataFrame({
    "Model": ["ElasticNet LR", "Random Forest", "CatBoost"],
    "Accuracy": [
        accuracy_score(y_encoded, y_pred_lr),
        accuracy_score(y_encoded, y_pred_rf),
        accuracy_score(y_encoded, y_pred_cat)
    ],
    "Macro F1": [
        f1_score(y_encoded, y_pred_lr, average="macro"),
        f1_score(y_encoded, y_pred_rf, average="macro"),
        f1_score(y_encoded, y_pred_cat, average="macro")
    ]
})

results

'''
## Predictive Modeling Summary

1. All models achieve strong classification performance
2. Linear models perform well due to effective feature selection
3. Tree ensembles capture nonlinear gene interactions
4. CatBoost provides the best overall accuracy and macro F1
5. Misclassifications mainly occur between biologically similar tumors

Conclusion:
Transcriptomic signatures enable accurate, multi-class brain tumor classification with a compact gene set.
'''
